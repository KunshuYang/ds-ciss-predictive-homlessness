{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\final_dataset.csv') \n",
    "\n",
    "# Group the data by CoC Name, Year, and Homelessness Type\n",
    "grouped = df.groupby(['CoC Name', 'Year', 'Homelessness.Type'])['Count'].sum().unstack(level='Homelessness.Type').reset_index()\n",
    "\n",
    "# Rename columns to match the expected format\n",
    "grouped = grouped.rename(columns={\n",
    "    'Overall.Homeless': 'Overall_Homeless',\n",
    "    'Sheltered.Total.Homeless': 'Sheltered',\n",
    "    'Unsheltered.Homeless': 'Unsheltered'\n",
    "})\n",
    "\n",
    "# Fill NaN values with 0\n",
    "grouped = grouped.fillna(0)\n",
    "\n",
    "# Convert data to the required format\n",
    "data = grouped.to_dict('records')\n",
    "\n",
    "# Create JavaScript code string\n",
    "js_data = f\"var data = {json.dumps(data)};\"\n",
    "\n",
    "# Read HTML template\n",
    "with open('templates/index.html', 'r', encoding='utf-8') as file:\n",
    "    html_template = file.read()\n",
    "\n",
    "# Insert data into HTML template\n",
    "html_with_data = html_template.replace('// INSERT_DATA_HERE', js_data)\n",
    "\n",
    "# Write the result to a new HTML file\n",
    "output_path = r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\project\\ds-ciss-predictive-homlessness\\Demo1\\homeless_data_visualization.html'\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(html_with_data)\n",
    "\n",
    "print(f\"HTML file has been generated: {output_path}\")\n",
    "\n",
    "# Verify the data was inserted into the HTML\n",
    "print(\"Data insertion verification:\")\n",
    "print(\"Data variable definition found:\" if \"var data = \" in html_with_data else \"Data variable definition NOT found\")\n",
    "print(\"First data item found:\" if str(data[0]) in html_with_data else \"First data item NOT found\")\n",
    "\n",
    "# Print the first few items of the processed data\n",
    "print(\"\\nProcessed data sample:\")\n",
    "print(json.dumps(data[:5], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data with calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 读取两个文件\n",
    "df_table3 = pd.read_csv(r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\10.20\\ACS_Data\\merged_final_data_cleaned.csv')\n",
    "df_table4 = pd.read_csv(r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\10.20\\data2\\poverty_cost_burden_rates_cleaned.csv')\n",
    "\n",
    "# 确保year列的类型一致\n",
    "df_table3['year'] = df_table3['year'].astype(float)\n",
    "df_table4['year'] = df_table4['year'].astype(float)\n",
    "\n",
    "# 在表3中添加表4的数据\n",
    "df_merged = pd.merge(\n",
    "    df_table3,\n",
    "    df_table4[['geo_id', 'year', 'CoC_Number', 'poverty_rate', 'cost_burden_rate']],\n",
    "    on=['geo_id', 'year', 'CoC_Number'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 重新排列列的顺序\n",
    "cols = list(df_table3.columns)  # 获取原始列顺序\n",
    "# 找到unemployment_rate和rental_vacancy_rate的位置\n",
    "rate_pos = cols.index('rental_vacancy_rate')\n",
    "# 在这个位置后插入新列\n",
    "new_cols = cols[:rate_pos+1] + ['poverty_rate', 'cost_burden_rate'] + cols[rate_pos+1:]\n",
    "\n",
    "# 按新的列顺序排列\n",
    "df_final = df_merged[new_cols]\n",
    "\n",
    "# 保存结果\n",
    "output_file = r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\10.20\\ACS_Data\\final_merged_data.csv'\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "# 显示一些统计信息\n",
    "print(\"合并结果统计：\")\n",
    "print(f\"总行数: {len(df_final)}\")\n",
    "print(\"\\n各比率的数据完整性：\")\n",
    "print(f\"unemployment_rate 非空值数量: {df_final['unemployment_rate'].notna().sum()}\")\n",
    "print(f\"rental_vacancy_rate 非空值数量: {df_final['rental_vacancy_rate'].notna().sum()}\")\n",
    "print(f\"poverty_rate 非空值数量: {df_final['poverty_rate'].notna().sum()}\")\n",
    "print(f\"cost_burden_rate 非空值数量: {df_final['cost_burden_rate'].notna().sum()}\")\n",
    "\n",
    "# 显示前几行数据来验证\n",
    "print(\"\\n合并后的数据示例（前几列）：\")\n",
    "print(df_final[['geo_id', 'year', 'unemployment_rate', 'rental_vacancy_rate', 'poverty_rate', 'cost_burden_rate']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate per capita data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv(r\"C:\\Users\\ykks\\Desktop\\zuoye\\spark\\model\\Final_estimate.csv\")\n",
    "\n",
    "# 假设原始数据中有以下列名，请根据您的实际数据列名进行修改：\n",
    "# \"Total Population\", \"Overall Homeless\", \"Overall Homeless Individuals\", \n",
    "# \"Overall Homeless People in Families\", \"Unsheltered Homeless\", \"Sheltered Total Homeless\"\n",
    "\n",
    "# 计算人均无家可归相关指标\n",
    "df[\"Overall_Homeless_Per_Capita\"] = df[\"Overall Homeless\"] / df[\"Total Population\"]\n",
    "df[\"Overall_Homeless_Individuals_Per_Capita\"] = df[\"Overall Homeless Individuals\"] / df[\"Total Population\"]\n",
    "df[\"Overall_Homeless_People_in_Families_Per_Capita\"] = df[\"Overall Homeless People in Families\"] / df[\"Total Population\"]\n",
    "df[\"Unsheltered_Homeless_Per_Capita\"] = df[\"Unsheltered Homeless\"] / df[\"Total Population\"]\n",
    "df[\"Sheltered_Homeless_Per_Capita\"] = df[\"Sheltered Total Homeless\"] / df[\"Total Population\"]\n",
    "\n",
    "# 如有需要，可将结果保存为新的CSV文件\n",
    "df.to_csv(r\"C:\\Users\\ykks\\Desktop\\zuoye\\spark\\model\\Final_estimate_per_capita.csv\", index=False)\n",
    "\n",
    "print(\"人均无家可归数据已成功计算并保存！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random_forest_model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 读取数据\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\ykks\\Desktop\\zuoye\\spark\\model\\Merged_Data.csv')\n",
    "\n",
    "# 过滤只包含 2010-2023 年的数据\n",
    "data = data[(data['Year'] >= 2010) & (data['Year'] <= 2023)]\n",
    "\n",
    "# 检查数据，去除缺失值\n",
    "print(data.info())\n",
    "data = data.dropna()\n",
    "\n",
    "# 对非数值型特征进行编码\n",
    "label_encoders = {}\n",
    "for column in data.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    data[column] = le.fit_transform(data[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# 定义不同的目标变量列表\n",
    "targets = ['Overall Homeless', 'Overall Homeless Individuals', 'Overall Homeless People in Families', 'Unsheltered Homeless', 'Sheltered Total Homeless']\n",
    "\n",
    "# 创建空的结果列表用于存储每个目标变量的评估结果\n",
    "results = []\n",
    "\n",
    "# 对每个目标变量进行预测和评估\n",
    "for target in targets:\n",
    "    # 特征和目标变量选择\n",
    "    X = data.drop(columns=targets)\n",
    "    y = data[target]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 创建随机森林回归模型\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 进行预测\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # 评估模型性能\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    results.append((target, mse, r2))\n",
    "\n",
    "# 打印所有目标变量的评估结果\n",
    "for target, mse, r2 in results:\n",
    "    print(f\"{target} - Mean Squared Error: {mse:.2e}, R-squared: {r2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
